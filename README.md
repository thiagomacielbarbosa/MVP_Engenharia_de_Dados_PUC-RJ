# MVP de Engenharia de Dados: BirdBase Analytics üê¶

Este projeto apresenta um pipeline completo de Engenharia de Dados (**End-to-End**) desenvolvido como MVP para a disciplina de Engenharia de Dados (PUC-Rio). O sistema ingere dados cient√≠ficos complexos sobre a biodiversidade avi√°ria global, normaliza as estruturas e disponibiliza um **Data Warehouse** anal√≠tico para estudos de conserva√ß√£o.

## üìã √çndice

- [Objetivo e Problema de Neg√≥cio](#-objetivo-e-problema-de-neg√≥cio)
- [Arquitetura da Solu√ß√£o](#-arquitetura-da-solu√ß√£o)
- [Modelagem de Dados](#-modelagem-de-dados)
- [Pipeline ETL](#-pipeline-etl)
- [Resultados e An√°lises](#-resultados-e-an√°lises)
- [Estrutura do Reposit√≥rio](#-estrutura-do-reposit√≥rio)
- [Como Executar](#-como-executar)

---

## üéØ Objetivo e Problema de Neg√≥cio

- **Contexto:** A base de dados **BirdBase** (Sekercioglu et al.) cont√©m informa√ß√µes vitais sobre ecologia, hist√≥ria de vida e risco de extin√ß√£o de mais de 11.000 esp√©cies de aves. No entanto, os dados originais s√£o disponibilizados em planilhas Excel desnormalizadas, com cabe√ßalhos complexos ("Double Headers") e legendas em texto livre.
- **O Problema:** Como estruturar esses dados para permitir an√°lises r√°pidas sobre a correla√ß√£o entre caracter√≠sticas biol√≥gicas (massa, dieta, migra√ß√£o) e o risco de extin√ß√£o?
- **A Solu√ß√£o:** Constru√ß√£o de um pipeline ETL no **Databricks** que baixa os dados da fonte oficial, trata inconsist√™ncias de formato e modela as informa√ß√µes em um **Esquema Estrela (Star Schema)**.

---

## üèó Arquitetura da Solu√ß√£o

O projeto segue a arquitetura **Lakehouse** (Bronze ‚Üí Silver ‚Üí Gold) simplificada para o MVP.

```mermaid
graph LR
    A[Fonte: Springer Nature / Figshare] -->|Ingest√£o Python + Pandas| B(Bronze: Dados Brutos em Mem√≥ria)
    B -->|PySpark: Limpeza e Tipagem| C(Silver: Staging Area)
    C -->|Modelagem Dimensional| D(Gold: Tabelas Delta)
    D -->|SQL Analytics| E[Dashboards e Insights]
```

- **Fonte:** Arquivo `BirdBase_Final.xlsx` (baixado programaticamente via script).
- **Processamento:** Cluster Databricks Community (Spark 3.x).
- **Bibliotecas:** `pyspark`, `pandas`, `openpyxl`, `requests`.
- **Armazenamento:** Delta Lake.
- **intelig√™ncia Artificial:** Uso do `Google Gemini` para auxilio em organiza√ß√£o e elabora√ß√£o de c√≥digos

---

## üß© Modelagem de Dados

Foi adotado o modelo dimensional **Star Schema** para facilitar consultas anal√≠ticas perform√°ticas.

### Tabela Fato

- **`FATO_METRICAS_AVES`**: Cont√©m as m√©tricas num√©ricas (Massa, Altitude, Tamanho de Ninhada).

### Tabelas Dimens√£o

- **`DIM_ESPECIE`**: Taxonomia b√°sica (Nome Ingl√™s, Latim, ID Original).
- **`DIM_CONSERVACAO`**: Status IUCN extra√≠do dinamicamente da legenda (ex: CR, EN, VU).
- **`DIM_HABITAT`**: Habitat prim√°rio padronizado.
- **`DIM_DIETA`**: Dieta prim√°ria padronizada.
- **`DIM_TAXONOMIA`**: Hierarquia de Ordem e Fam√≠lia.

> _Para detalhes t√©cnicos de cada coluna e tipagem, consulte o arquivo `CATALOGO.md`._

---

## ‚öôÔ∏è Pipeline ETL

O script `1_Pipeline_ETL.py` executa as seguintes etapas cr√≠ticas para garantir a robustez do dado:

1.  **Ingest√£o Resiliente:** O script verifica se o arquivo existe localmente; caso contr√°rio, realiza o download autom√°tico da URL oficial da Springer Nature/Figshare.
2.  **Tratamento de "Double Header":** O Excel original possui categorias na Linha 1 e os nomes reais das colunas na Linha 2. O script utiliza pandas com `header=1` para resolver isso.
3.  **Parsing de Legenda N√£o Estruturada:** Um algoritmo varre a aba de legendas (que cont√©m texto livre) para encontrar a linha exata onde come√ßa a tabela de c√≥digos da IUCN.
4.  **Sanitiza√ß√£o de Nomes:** Tratamento de colunas com caracteres especiais (ex: `English Name (BirdLife > IOC > Clements>AviList)`) utilizando backticks no Spark.
5.  **Limpeza de Tipos (`try_cast`):** Convers√£o segura de colunas num√©ricas (como _Average Mass_ e _Clutch Size_) para evitar falhas de execu√ß√£o devido a caracteres sujos no Excel.
6.  **Qualidade:** Tratamento de valores nulos (`fillna`) e padroniza√ß√£o de strings (`UPPER`/`TRIM`).

---

## üìä Resultados e An√°lises

As an√°lises foram realizadas via SQL (ver `2_Analise_SQL.sql`). Abaixo, exemplos dos insights gerados:

1.  **Conserva√ß√£o por Fam√≠lia:** Identifica√ß√£o das fam√≠lias taxon√¥micas com maior propor√ß√£o de esp√©cies amea√ßadas.
2.  **Impacto da Dieta:** An√°lise da rela√ß√£o entre dieta prim√°ria e massa corporal m√©dia.
3.  **Check de Qualidade:** O pipeline garantiu 0 falhas de integridade referencial (√≥rf√£os) e consist√™ncia num√©rica.

---

## üìÇ Estrutura do Reposit√≥rio

```text
/
‚îú‚îÄ‚îÄ README.md                 # Documenta√ß√£o principal (Este arquivo)
‚îú‚îÄ‚îÄ Cat√°logo.md               # Dicion√°rio de dados detalhado
‚îú‚îÄ‚îÄ AutoAvalia√ß√£o.md          # Reflex√£o e autoavalia√ß√£o do aluno
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 1_Pipeline_ETL_Engenharia.ipynb     # C√≥digo Fonte do ETL (PySpark)
‚îÇ   ‚îî‚îÄ‚îÄ 2_Analise_SQL.ipynb    # Consultas de An√°lise e Qualidade
‚îÇ
‚îî‚îÄ‚îÄ evidencias/               # Screenshots e gr√°ficos gerados
    ‚îú‚îÄ‚îÄ 1- AN√ÅLISE DE CONSERVA√á√ÉO POR FAM√çLIA.png
    ‚îú‚îÄ‚îÄ 2- RELA√á√ÉO DIETA vs. MASSA CORPORAL.png
    ‚îú‚îÄ‚îÄ 3- HABITAT DAS ESP√âCIES AMEA√áADAS.png
    ‚îî‚îÄ‚îÄ ...
```

## üöÄ Como Executar

Para reproduzir este projeto no seu ambiente Databricks:

1.  Clone este reposit√≥rio.
2.  No **Databricks Workspace**, importe os arquivos da pasta `/notebooks`.
3.  Execute o notebook `1_Pipeline_ETL`.
    > **Nota:** Ele instalar√° automaticamente a depend√™ncia `openpyxl`, baixar√° os dados e criar√° as tabelas Delta.
4.  Execute o notebook `2_Analise_SQL` para visualizar os insights e gr√°ficos.
