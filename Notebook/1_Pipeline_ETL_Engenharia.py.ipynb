{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "744064e4-9ae8-4681-8fb9-358b0dcea451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MVP ENGENHARIA DE DADOS - PIPELINE ETL (BirdBase Springernature)\n",
    "\n",
    "**Autor:** Thiago Maciel Barbosa  \n",
    "**Descrição:** Pipeline robusto para tratar \"Double Headers\" e Legendas não estruturadas. Inclui download automático do Figshare/Springernature.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8069190f-51fe-4b58-894e-baed0208aeaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c319b5ad-9764-4fcd-9bf8-160419e972e2/lib/python3.12/site-packages (3.1.5)\nRequirement already satisfied: et-xmlfile in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c319b5ad-9764-4fcd-9bf8-160419e972e2/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n--- INICIANDO INGESTÃO DE DADOS ---\nTentando baixar arquivo da fonte: https://springernature.figshare.com/ndownloader/files/55634729\nDownload concluído! Arquivo salvo em: /tmp/BirdBase_Final.xlsx\n>> Lendo aba 'Data' e tratando cabeçalho duplo...\n>> Lendo aba 'Legend' e extraindo tabela de status...\n   Legenda extraída com sucesso. 137 categorias encontradas.\n>> Convertendo Pandas para Spark DataFrames...\nIngestão concluída com sucesso!\n\n--- INICIANDO TRANSFORMAÇÃO ---\n\n--- INICIANDO MODELAGEM ---\nGerando Tabela Fato...\n\n--- SALVANDO TABELAS DELTA ---\nCriando/Verificando banco de dados 'birdbase'...\nSalvando dim_habitat...\nSalvando dim_dieta...\nSalvando dim_taxonomia...\nSalvando dim_conservacao...\nSalvando dim_especie...\nSalvando fato_metricas_aves...\nPipeline BirdBase concluído com sucesso! Tabelas salvas no banco 'birdbase'.\n"
     ]
    }
   ],
   "source": [
    "# Biblioteca para ler o XLSX\n",
    "%pip install openpyxl\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "from pyspark.sql.functions import col, when, trim, upper, monotonically_increasing_id, expr\n",
    "from pyspark.sql.types import FloatType, IntegerType, StringType\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. INGESTÃO DE DADOS\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Configurações\n",
    "# URL fornecida: Link de download direto do Figshare\n",
    "URL_FONTE = \"https://springernature.figshare.com/ndownloader/files/55634729\"\n",
    "# Caminho onde o arquivo será salvo temporariamente no Driver do Cluster\n",
    "CAMINHO_TEMPORARIO = \"/tmp/BirdBase_Final.xlsx\"\n",
    "\n",
    "print(\"--- INICIANDO INGESTÃO DE DADOS ---\")\n",
    "\n",
    "try:\n",
    "    print(f\"Tentando baixar arquivo da fonte: {URL_FONTE}\")\n",
    "    \n",
    "    # O parametro allow_redirects=True é crucial para links do Figshare\n",
    "    response = requests.get(URL_FONTE, allow_redirects=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Salvando o arquivo no disco local do driver para o Pandas ler\n",
    "    with open(CAMINHO_TEMPORARIO, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    print(f\"Download concluído! Arquivo salvo em: {CAMINHO_TEMPORARIO}\")\n",
    "    arquivo_para_ler = CAMINHO_TEMPORARIO\n",
    "\n",
    "    # --- TRATAMENTO DA ABA 'DATA' (CABEÇALHO DUPLO) ---\n",
    "    print(\">> Lendo aba 'Data' e tratando cabeçalho duplo...\")\n",
    "    # header=1: Ignora a linha 0 (Categorias macro) e usa a linha 1 como cabeçalho\n",
    "    # engine='openpyxl': Força o uso da biblioteca que acabamos de instalar\n",
    "    pdf_data = pd.read_excel(arquivo_para_ler, sheet_name=\"Data\", header=1, engine='openpyxl')\n",
    "    \n",
    "    # --- TRATAMENTO DA ABA 'LEGEND' (TEXTO NÃO ESTRUTURADO) ---\n",
    "    print(\">> Lendo aba 'Legend' e extraindo tabela de status...\")\n",
    "    pdf_legend_raw = pd.read_excel(arquivo_para_ler, sheet_name=\"Legend\", header=None, engine='openpyxl')\n",
    "    \n",
    "    # Procuramos a linha que contém \"IUCN Red List Status\"\n",
    "    try:\n",
    "        # Busca dinâmica pelo texto-chave\n",
    "        start_row_index = pdf_legend_raw[pdf_legend_raw[0].astype(str).str.contains(\"IUCN Red List Status\", na=False)].index[0]\n",
    "        \n",
    "        # Recarrega a aba Legend pulando as linhas de texto inútil\n",
    "        pdf_legend = pd.read_excel(arquivo_para_ler, sheet_name=\"Legend\", header=start_row_index + 1, engine='openpyxl')\n",
    "        \n",
    "        # Seleciona apenas as colunas de Código e Descrição\n",
    "        pdf_legend = pdf_legend.iloc[:, 0:2]\n",
    "        pdf_legend.columns = [\"Code\", \"Description\"]\n",
    "        pdf_legend = pdf_legend.dropna() # Remove linhas vazias\n",
    "        print(f\"   Legenda extraída com sucesso. {len(pdf_legend)} categorias encontradas.\")\n",
    "    except IndexError:\n",
    "        print(\"   AVISO: Não foi possível encontrar a tabela de legenda automaticamente. Criando DataFrame vazio.\")\n",
    "        pdf_legend = pd.DataFrame(columns=[\"Code\", \"Description\"])\n",
    "\n",
    "    # --- CONVERSÃO PARA SPARK ---\n",
    "    print(\">> Convertendo Pandas para Spark DataFrames...\")\n",
    "    # Conversão para string para evitar erros. A tipagem correta (Float/Int) será feita na etapa de Transformação\n",
    "    df_raw = spark.createDataFrame(pdf_data.astype(str))\n",
    "    df_legend_spark = spark.createDataFrame(pdf_legend.astype(str))\n",
    "    \n",
    "    print(\"Ingestão concluída com sucesso!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERRO FATAL NA INGESTÃO: {e}\")\n",
    "    raise e\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. TRANSFORMAÇÃO E LIMPEZA\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- INICIANDO TRANSFORMAÇÃO ---\")\n",
    "\n",
    "# Seleção e Renomeação (Mapeamento De -> Para)\n",
    "# Usamos crases (backticks) para lidar com os nomes complexos do Excel original\n",
    "df_selecionado = df_raw.select(\n",
    "    col(\"`IOC 15.1`\").cast(StringType()).alias(\"id_original\"),\n",
    "    col(\"`English Name (BirdLife > IOC > Clements>AviList)`\").alias(\"nome_ingles\"),\n",
    "    col(\"`Latin (BirdLife > IOC > Clements>AviList)`\").alias(\"nome_latin\"),\n",
    "    \n",
    "    # Taxonomia\n",
    "    col(\"`Order`\").alias(\"ordem\"),\n",
    "    col(\"`Family IOC 15.1`\").alias(\"familia\"),\n",
    "    \n",
    "    # Conservação\n",
    "    col(\"`2024 IUCN Red List category`\").alias(\"cod_categoria_iucn\"),\n",
    "    \n",
    "    # Habitat e Dieta\n",
    "    col(\"`Primary Habitat`\").alias(\"habitat_primario\"),\n",
    "    col(\"`Primary Diet`\").alias(\"dieta_primaria\"),\n",
    "    \n",
    "    # Métricas Físicas\n",
    "    col(\"`Average Mass`\").alias(\"massa_media\"),\n",
    "    col(\"`NormMin`\").alias(\"altitude_min\"),\n",
    "    col(\"`NormMax`\").alias(\"altitude_max\"),\n",
    "    \n",
    "    # Reprodução\n",
    "    col(\"`Clutch_Min`\").alias(\"ninhada_min\"),\n",
    "    col(\"`Clutch_Max`\").alias(\"ninhada_max\"),\n",
    "    \n",
    "    # Comportamento\n",
    "    col(\"`Mig`\").alias(\"flag_migratorio\"),\n",
    "    col(\"`Sed`\").alias(\"flag_sedentario\"),\n",
    "    \n",
    "    # Detalhe da Dieta\n",
    "    col(\"`IN-Wt`\").alias(\"peso_dieta_inseto\"),\n",
    "    col(\"`FR-Wt`\").alias(\"peso_dieta_fruta\")\n",
    ")\n",
    "\n",
    "# Conversão Segura de Tipos (try_cast via expr)\n",
    "# Isso garante que se houver texto onde deveria ter número, vira NULL em vez de erro\n",
    "df_convertido = df_selecionado.select(\n",
    "    col(\"id_original\"), col(\"nome_ingles\"), col(\"nome_latin\"), \n",
    "    col(\"ordem\"), col(\"familia\"), col(\"cod_categoria_iucn\"), \n",
    "    col(\"habitat_primario\"), col(\"dieta_primaria\"),\n",
    "    \n",
    "    expr(\"try_cast(massa_media AS FLOAT)\").alias(\"massa_media\"),\n",
    "    expr(\"try_cast(altitude_min AS FLOAT)\").alias(\"altitude_min\"), \n",
    "    expr(\"try_cast(altitude_max AS FLOAT)\").alias(\"altitude_max\"),\n",
    "    expr(\"try_cast(ninhada_min AS FLOAT)\").alias(\"ninhada_min\"),\n",
    "    expr(\"try_cast(ninhada_max AS FLOAT)\").alias(\"ninhada_max\"),\n",
    "    expr(\"try_cast(peso_dieta_inseto AS FLOAT)\").alias(\"peso_dieta_inseto\"), \n",
    "    expr(\"try_cast(peso_dieta_fruta AS FLOAT)\").alias(\"peso_dieta_fruta\"),\n",
    "    \n",
    "    col(\"flag_migratorio\"), col(\"flag_sedentario\")\n",
    ")\n",
    "\n",
    "# Tratamento de Nulos\n",
    "df_tratado = df_convertido.fillna(0, subset=[\n",
    "    \"massa_media\", \"altitude_min\", \"altitude_max\", \n",
    "    \"ninhada_min\", \"ninhada_max\", \"peso_dieta_inseto\", \"peso_dieta_fruta\"\n",
    "])\n",
    "\n",
    "# Lógica de Negócio (Flags Booleanas e Padronização)\n",
    "# Convertendo '1'/'True' para booleano real e padronizando texto para maiúsculo\n",
    "df_tratado = df_tratado.withColumn(\"eh_migratorio\", when(col(\"flag_migratorio\").isin(\"1\", \"1.0\", \"True\"), True).otherwise(False)) \\\n",
    "                       .withColumn(\"eh_sedentario\", when(col(\"flag_sedentario\").isin(\"1\", \"1.0\", \"True\"), True).otherwise(False)) \\\n",
    "                       .withColumn(\"habitat_primario\", upper(trim(col(\"habitat_primario\")))) \\\n",
    "                       .withColumn(\"dieta_primaria\", upper(trim(col(\"dieta_primaria\")))) \\\n",
    "                       .withColumn(\"cod_categoria_iucn\", upper(trim(col(\"cod_categoria_iucn\"))))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. MODELAGEM (STAR SCHEMA)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- INICIANDO MODELAGEM ---\")\n",
    "\n",
    "# DIM_CONSERVACAO\n",
    "df_dim_conservacao = df_legend_spark.select(\n",
    "    upper(trim(col(\"Code\"))).alias(\"cod_categoria_iucn\"),\n",
    "    col(\"Description\").alias(\"desc_status\")\n",
    ").distinct()\n",
    "df_dim_conservacao = df_dim_conservacao.withColumn(\"sk_status_iucn\", monotonically_increasing_id())\n",
    "\n",
    "# DIM_HABITAT\n",
    "df_dim_habitat = df_tratado.select(\"habitat_primario\").distinct().filter(col(\"habitat_primario\").isNotNull())\n",
    "df_dim_habitat = df_dim_habitat.withColumn(\"sk_habitat\", monotonically_increasing_id())\n",
    "\n",
    "# DIM_DIETA\n",
    "df_dim_dieta = df_tratado.select(\"dieta_primaria\").distinct().filter(col(\"dieta_primaria\").isNotNull())\n",
    "df_dim_dieta = df_dim_dieta.withColumn(\"sk_dieta\", monotonically_increasing_id())\n",
    "\n",
    "# DIM_TAXONOMIA\n",
    "df_dim_taxonomia = df_tratado.select(\"familia\", \"ordem\").distinct()\n",
    "df_dim_taxonomia = df_dim_taxonomia.withColumn(\"sk_familia\", monotonically_increasing_id())\n",
    "\n",
    "# DIM_ESPECIE\n",
    "df_dim_especie = df_tratado.select(\"id_original\", \"nome_ingles\", \"nome_latin\").distinct()\n",
    "df_dim_especie = df_dim_especie.withColumn(\"sk_especie\", monotonically_increasing_id())\n",
    "\n",
    "print(\"Gerando Tabela Fato...\")\n",
    "\n",
    "# Joins para substituir valores originais pelas Chaves (SKs)\n",
    "df_fato = df_tratado.alias(\"t\") \\\n",
    "    .join(df_dim_especie.alias(\"de\"), col(\"t.id_original\") == col(\"de.id_original\"), \"left\") \\\n",
    "    .join(df_dim_habitat.alias(\"dh\"), col(\"t.habitat_primario\") == col(\"dh.habitat_primario\"), \"left\") \\\n",
    "    .join(df_dim_dieta.alias(\"dd\"), col(\"t.dieta_primaria\") == col(\"dd.dieta_primaria\"), \"left\") \\\n",
    "    .join(df_dim_taxonomia.alias(\"dt\"), (col(\"t.familia\") == col(\"dt.familia\")) & (col(\"t.ordem\") == col(\"dt.ordem\")), \"left\") \\\n",
    "    .join(df_dim_conservacao.alias(\"dc\"), col(\"t.cod_categoria_iucn\") == col(\"dc.cod_categoria_iucn\"), \"left\")\n",
    "\n",
    "# Seleção final das colunas da Fato\n",
    "df_fato_final = df_fato.select(\n",
    "    col(\"de.sk_especie\"),\n",
    "    col(\"dh.sk_habitat\"),\n",
    "    col(\"dd.sk_dieta\"),\n",
    "    col(\"dt.sk_familia\"),\n",
    "    col(\"dc.sk_status_iucn\"),\n",
    "    col(\"t.massa_media\"),\n",
    "    col(\"t.ninhada_min\"),\n",
    "    col(\"t.ninhada_max\"),\n",
    "    col(\"t.altitude_min\"),\n",
    "    col(\"t.altitude_max\"),\n",
    "    col(\"t.eh_migratorio\"),\n",
    "    col(\"t.eh_sedentario\"),\n",
    "    col(\"t.peso_dieta_inseto\"),\n",
    "    col(\"t.peso_dieta_fruta\")\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. CARGA (SALVANDO NO DELTA LAKE)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- SALVANDO TABELAS DELTA ---\")\n",
    "\n",
    "# 1. CRIAR O BANCO DE DADOS (SCHEMA)\n",
    "print(\"Criando/Verificando banco de dados 'birdbase'...\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS birdbase\")\n",
    "\n",
    "# 2. SALVAR AS TABELAS DENTRO DO BANCO\n",
    "\n",
    "print(\"Salvando dim_habitat...\")\n",
    "df_dim_habitat.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"birdbase.dim_habitat\")\n",
    "print(\"Salvando dim_dieta...\")\n",
    "df_dim_dieta.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"birdbase.dim_dieta\")\n",
    "print(\"Salvando dim_taxonomia...\")\n",
    "df_dim_taxonomia.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"birdbase.dim_taxonomia\")\n",
    "print(\"Salvando dim_conservacao...\")\n",
    "df_dim_conservacao.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"birdbase.dim_conservacao\")\n",
    "print(\"Salvando dim_especie...\")\n",
    "df_dim_especie.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"birdbase.dim_especie\")\n",
    "print(\"Salvando fato_metricas_aves...\")\n",
    "df_fato_final.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"birdbase.fato_metricas_aves\")\n",
    "print(\"Pipeline BirdBase concluído com sucesso! Tabelas salvas no banco 'birdbase'.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8439178576403979,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1_Pipeline_ETL_Engenharia.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
